{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from overrides import overrides\n",
    "from typing import Iterable, Dict, List\n",
    "import jsonlines\n",
    "import warnings\n",
    "\n",
    "from allennlp.models.archival import load_archive\n",
    "# from allennlp.models.basic_classifier import BasicClassifier\n",
    "# from allennlp.modules.seq2vec_encoders.cnn_encoder import CnnEncoder\n",
    "# from allennlp.modules import FeedForward, Seq2SeqEncoder, Seq2VecEncoder, TextFieldEmbedder\n",
    "from allennlp.predictors import Predictor #, TextClassifierPredictor\n",
    "\n",
    "from allennlp.data import DatasetReader, Instance, TokenIndexer, Vocabulary #Tokenizer,\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token #, Tokenizer, WordTokenizer\n",
    "from allennlp.data.fields import MetadataField, TextField, LabelField\n",
    "\n",
    "from allennlp.common.util import JsonDict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModalityDatasetReader(DatasetReader):\n",
    "    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:\n",
    "        super().__init__()\n",
    "        self._token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        logger.info(\"Reading Modal Sense instances from {}\".format(file_path))\n",
    "        with open(file_path,\"r\") as file:\n",
    "            for line in file:\n",
    "                json_line = json.loads(line)\n",
    "                json_line.pop(\"modal_verb\", None)\n",
    "                yield self.sentence_to_instance(**json_line)\n",
    "    \n",
    "    @overrides\n",
    "    def text_to_instance(self, sentence:List[str], label:str=None) -> Instance:\n",
    "        instance_dict = {\"tokens\": TextField(sentence, self._token_indexers)}\n",
    "        \n",
    "        if label is not None:\n",
    "            instance_dict[\"label\"] = LabelField(label)\n",
    "\n",
    "        return Instance(instance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModalityPredictor(Predictor):\n",
    "\n",
    "    @overrides\n",
    "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
    "        sentence = json_dict[\"tokens\"]\n",
    "        if not hasattr(self._dataset_reader, \"tokenizer\") and not hasattr(\n",
    "            self._dataset_reader, \"_tokenizer\"\n",
    "        ):\n",
    "            sentence = [Token(t) for t in sentence.split()]            \n",
    "        return self._dataset_reader.text_to_instance(sentence=sentence)\n",
    "\n",
    "    \n",
    "    def predict(self, sentence: str) -> JsonDict:\n",
    "        return self.predict_json({\"tokens\": sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_mv_and_labels_counts(targets):\n",
    "    modal_targets = {t: {\"total\": 0, \"errors\": 0} for t in targets}\n",
    "\n",
    "    labels = {\n",
    "        \"dy\": {\"total\": 0, \"errors\": 0},\n",
    "        \"de\": {\"total\": 0, \"errors\": 0},\n",
    "        \"ep\": {\"total\": 0, \"errors\": 0}\n",
    "    }\n",
    "    return modal_targets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def collect_errors_and_accuarcy(filepath):\n",
    "    labels_golds = {\"de\": [1,0,0], \"ep\": [0,1,0], \"dy\": [0,0,1]}\n",
    "    with jsonlines.open(filepath, \"r\") as src:\n",
    "        all_modal_targets = {line['modal_verb'].lower() for line in src}\n",
    "        modal_verbs, labels = reset_mv_and_labels_counts(all_modal_targets)\n",
    "    with jsonlines.open(filepath, \"r\") as test:\n",
    "        predictions, golds = [], []\n",
    "        for line in test:\n",
    "            try:\n",
    "                prediction = predictor.predict(sentence=line[\"sentence\"])\n",
    "                predicted_label = prediction[\"label\"]\n",
    "                gold = line[\"label\"]\n",
    "                mv = line[\"modal_verb\"].lower()\n",
    "                modal_verbs[mv][\"total\"] += 1\n",
    "                labels[gold][\"total\"] += 1\n",
    "                if gold != predicted_label:\n",
    "                    modal_verbs[mv][\"errors\"] += 1\n",
    "                    labels[gold][\"errors\"] += 1\n",
    "                predictions.append(prediction[\"probs\"])\n",
    "                golds.append(labels_golds[gold])\n",
    "            except RuntimeError:\n",
    "                sent, l = line[\"sentence\"], line[\"label\"]\n",
    "                warnings.warn(f\"sentence too short: {sent}, {l}\")\n",
    "\n",
    "        print(accuracy(np.array(predictions), np.array(golds)))\n",
    "    return  modal_verbs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return 100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: .*linear_layers.*weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BasicClassifier(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2vec_encoder): CnnEncoder(\n",
       "    (_activation): ReLU()\n",
       "    (conv_layer_0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (conv_layer_1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (conv_layer_2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (_classification_layer): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = load_archive(\"../../models/gme_all/model.tar.gz\", cuda_device=1)  \n",
    "model = archive.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: .*linear_layers.*weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BasicClassifier(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2vec_encoder): CnnEncoder(\n",
       "    (_activation): ReLU()\n",
       "    (conv_layer_0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (conv_layer_1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (conv_layer_2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (_classification_layer): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = load_archive(\"../../models/epos_balanced/model.tar.gz\", cuda_device=1)  \n",
    "model = archive.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ModalityPredictor(model, dataset_reader=ModalityDatasetReader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.40298507462687\n"
     ]
    }
   ],
   "source": [
    "modal_targets, labels = collect_errors_and_accuarcy(\"../../data/GME/test_modal-BIOSE-coarse.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/shovalsa/anaconda3/envs/modalvenv/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: sentence too short: must be really expensive, ep\n",
      "/home/nlp/shovalsa/anaconda3/envs/modalvenv/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: sentence too short: Maybe you can ., dy\n",
      "/home/nlp/shovalsa/anaconda3/envs/modalvenv/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: sentence too short: I may now ., de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.573407202216066\n"
     ]
    }
   ],
   "source": [
    "modal_targets, labels = collect_errors_and_accuarcy(\"../../data/EPOS_E/test_EPOS+MPQA_re-balanced.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'could': {'total': 38, 'errors': 18},\n",
       " 'can': {'total': 54, 'errors': 45},\n",
       " 'shall': {'total': 3, 'errors': 2},\n",
       " 'must': {'total': 116, 'errors': 15},\n",
       " 'should': {'total': 28, 'errors': 3},\n",
       " 'may': {'total': 122, 'errors': 10}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
